{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWA0xSKyfeT_",
    "outputId": "393f8bf5-8441-47c4-ce12-2815770ea686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-addons in /home/batman/.local/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/batman/.local/lib/python3.8/site-packages (from tensorflow-addons) (2.10.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dwxfYNiUep7q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Activation, Conv2D, Dropout, MaxPooling2D, Flatten, Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rZKCLBreeuRl"
   },
   "outputs": [],
   "source": [
    "#! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00gKm6gAev-Z",
    "outputId": "0122556c-3988-4d0e-d102-5c2e945c230f"
   },
   "outputs": [],
   "source": [
    "#! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8bBDJLoJeyAY"
   },
   "outputs": [],
   "source": [
    "#! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sUhsXqdreyDL"
   },
   "outputs": [],
   "source": [
    "#! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7CWDnK8eyGk",
    "outputId": "b8c0e35f-46c1-48bf-c1ec-ba58f4588224"
   },
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d hereisburak/pins-face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWmo_gCZeyJc",
    "outputId": "54217640-54c3-4351-92d6-71ad67f053f4"
   },
   "outputs": [],
   "source": [
    "#! unzip pins-face-recognition.zip -d pins-face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "didIE0NQep7u"
   },
   "outputs": [],
   "source": [
    "directory = \"/home/batman/Desktop/face_recog/train/content/pins-face-recognition/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NCdxHoGuep7v"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224,224,3)\n",
    "batch_size = 64\n",
    "EPOCHS = 50\n",
    "base_output = \"/content/output\"\n",
    "MODEL_PATH = os.path.sep.join([base_output, \"siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([base_output, \"plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Tv2Qdy72ep7v"
   },
   "outputs": [],
   "source": [
    "def build_siamese_model(inputShape, embeddingDim=48):\n",
    "    # specify the inputs for the feature extractor network\n",
    "    inputs = Input(inputShape)\n",
    "    classifier= Sequential()\n",
    "    classifier.add(Convolution2D(32, kernel_size=(3, 3), strides=(1, 1), input_shape=(224,224,3), activation='relu'))\n",
    "    classifier.add(Convolution2D(32, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    classifier.add(Convolution2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(64, kernel_size=(3,3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    classifier.add(Convolution2D(128, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(128, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "    \n",
    "    classifier.add(Convolution2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(Convolution2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "    classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    classifier.add(Flatten())\n",
    "    \n",
    "    classifier.add(Dense(4096, activation='relu'))\n",
    "    classifier.add(keras.layers.Dropout(0.5))\n",
    "    classifier.add(Dense(4096, activation='relu'))\n",
    "    classifier.add(keras.layers.Dropout(0.5))\n",
    "    classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
    "    # prepare the final outputs\n",
    "    classifier.add(GlobalAveragePooling2D())\n",
    "    output = classifier.add(Dense(embeddingDim))\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "461uVfROep7w"
   },
   "outputs": [],
   "source": [
    "def make_pairs(images, labels):\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pairImages = []\n",
    "    pairLabels = []\n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    \n",
    "    unique_label = np.unique(labels)\n",
    "    idx = {}\n",
    "    print(len(unique_label))\n",
    "    for i in range(len(unique_label)):\n",
    "        ind = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j] == unique_label[i]:\n",
    "                ind.append(j)\n",
    "        idx[unique_label[i]] = ind\n",
    "    # loop over all images\n",
    "    for idxA in range(len(images)):\n",
    "        # grab the current image and label belonging to the current\n",
    "        # iteration\n",
    "        currentImage = images[idxA]\n",
    "        label = labels[idxA]\n",
    "        # randomly pick an image that belongs to the *same* class\n",
    "        # label\n",
    "        temp_lis = idx[label]\n",
    "        idxB = random.choice(temp_lis)\n",
    "        posImage = images[idxB]\n",
    "        # prepare a positive pair and update the images and labels\n",
    "        # lists, respectively\n",
    "        pairImages.append([currentImage, posImage])\n",
    "        pairLabels.append([1])\n",
    "        # grab the indices for each of the class labels *not* equal to\n",
    "        # the current label and randomly pick an image corresponding\n",
    "        # to a label *not* equal to the current label\n",
    "        negIdx = np.where(labels != label)[0]\n",
    "        negImage = images[np.random.choice(negIdx)]\n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pairImages.append([currentImage, negImage])\n",
    "        pairLabels.append([0])\n",
    "    # return a 2-tuple of our image pairs and labels\n",
    "    return (np.array(pairImages), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1KO2JfL9ep7x"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HkL8MxqCep7z"
   },
   "outputs": [],
   "source": [
    "# images = []\n",
    "# label = []\n",
    "# for i in tqdm(os.listdir(directory)):\n",
    "#     lbl = i[5:]\n",
    "#     p = os.path.join(directory,i)\n",
    "#     print(i)\n",
    "#     for j in tqdm(os.listdir(p)):\n",
    "#         print(j)\n",
    "#         img= cv2.imread(os.path.join(p, j))\n",
    "#         img2 = cv2.resize(img,(224,224))\n",
    "#         images+=img2\n",
    "#         label += lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eeh8sYKuep71"
   },
   "outputs": [],
   "source": [
    "# def detect_face(image):\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "#     # Draw rectangle around the faces and crop the faces\n",
    "#     for (x, y, w, h) in faces:\n",
    "#         cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "#         faces = image[y:y + h, x:x + w]\n",
    "#         #cv2.imshow(\"face\",faces)\n",
    "#     #print(faces)\n",
    "# #     cv2.imshow(\"face\", faces)\n",
    "# #     cv2.waitKey(0)\n",
    "# #     cv2.destroyAllWindows()\n",
    "#     return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0NVdsWFep72",
    "outputId": "13947f81-0a1c-4127-c8a0-773a1cec941f"
   },
   "outputs": [],
   "source": [
    "# images=[]\n",
    "# label=[]\n",
    "# count=0\n",
    "# for file in tqdm(os.listdir(directory)):\n",
    "#     if file == 'Untitled.ipynb' or file == '.ipynb_checkpoints':\n",
    "#         continue\n",
    "        \n",
    "#     path=os.path.join(directory,file)\n",
    "#     name = file[5:]\n",
    "#     for im in os.listdir(path):\n",
    "#         image=cv2.imread(os.path.join(path,im))\n",
    "#         #image2=mtcnn_detector(image)\n",
    "#         image2 = detect_face(image)\n",
    "# #         if type(image2) == \"<class 'tuple'>\":\n",
    "# #             continue\n",
    "        \n",
    "#         if image2 == ():\n",
    "#             continue\n",
    "#         #if image2.shape[0]>10 and image2.shape[1]>10:\n",
    "#         image3=cv2.resize(image2,(224,224))\n",
    "#         # image3 = image3/255\n",
    "#         images+=[image3]\n",
    "#         label+=[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DO2H2xStdM93"
   },
   "outputs": [],
   "source": [
    "#!unzip train.zip -d train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JyK4uj6xdYDG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:24<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "label = []\n",
    "for file in tqdm(os.listdir(directory)):\n",
    "    path = directory + \"/\" + file\n",
    "    for img in os.listdir(path):\n",
    "        p = path + \"/\" + img\n",
    "        image = cv2.imread(p)\n",
    "        images.append(image)\n",
    "        label.append(file[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwwmOLnRep73",
    "outputId": "4a56b3d8-a39a-4175-e1ad-c71dfb0fdeb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17514\n",
      "17514\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPQpXWGTep74",
    "outputId": "70da690c-b3f3-45be-8eb4-3e3b89674039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17514\n"
     ]
    }
   ],
   "source": [
    "n=len(images)\n",
    "print(n)\n",
    "D=list(range(n))\n",
    "random.seed(2021)\n",
    "random.shuffle(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8PnFYZeep74"
   },
   "outputs": [],
   "source": [
    "trainY=np.array(label)[D[0:(n//4)*3]]\n",
    "testY=np.array(label)[D[(n//4)*3:]]\n",
    "trainX=np.array(images)[D[0:(n//4)*3]]\n",
    "testX=np.array(images)[D[(n//4)*3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rQO-OwRep75",
    "outputId": "019daea3-5488-43f6-f453-c145ee7efed1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# testX = testX / 255.0\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "# prepare the positive and negative pairs\n",
    "print(\"[INFO] preparing positive and negative pairs...\")\n",
    "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
    "(pairTest, labelTest) = make_pairs(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d3D-bi2UObI"
   },
   "outputs": [],
   "source": [
    "print(pairTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1kKhGbMpep75"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] building siamese network...\")\n",
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSLCYrGbep76"
   },
   "outputs": [],
   "source": [
    "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiPbCWxgep76"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "    [pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
    "    validation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5FXmZYpep76"
   },
   "outputs": [],
   "source": [
    "def plot_training(H, plotPath):\n",
    "    # construct a plot that plots and saves the training history\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFo9zwTAep77"
   },
   "outputs": [],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving siamese model...\")\n",
    "model.save(MODEL_PATH)\n",
    "# plot the training history\n",
    "print(\"[INFO] plotting training history...\")\n",
    "plot_training(history, PLOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deLF3UK7ep77"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "siamese.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
